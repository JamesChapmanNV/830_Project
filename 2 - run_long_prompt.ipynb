{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a8a75de",
   "metadata": {},
   "source": [
    "# Long Prompt\n",
    "<br>\n",
    "James Chapman<br>\n",
    "CIS 830 Advanced Topics in AI – Term Project<br>\n",
    "Kansas State University<br><br>\n",
    "\n",
    "This notebook classifies social media posts for ILLICIT/ABUSIVE drug use.<br>\n",
    "\n",
    "- Uses 'long_prompt'\n",
    "- Runs 4 LLMs (2 Paid Services & 2 Local HuggingFace Models)\n",
    "    - o4-mini \n",
    "    - GPT-4o-mini\n",
    "    - Meta-Llama-3.1-8B-Instruct\n",
    "    - Qwen-4B\n",
    "\n",
    "*** Saves response from every LLM call in separate text files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4579da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from utils import (\n",
    "    get_tweets_dataset, \n",
    "    extract_responses,\n",
    "    extract_JSON_labels_and_explanations,\n",
    "    extract_drug_labels,\n",
    "    extract_T_F_labels, \n",
    "    match_terms,\n",
    "    get_confusion_matrix_and_metrics,\n",
    ")\n",
    "from llm_manager import (\n",
    "    run_prompt_on_llm,\n",
    "### paid #################\n",
    "    # get_claude_response, \n",
    "    # get_openai_response, \n",
    "    # get_perplexity_response,\n",
    "    get_openai_gpt4omini_response,\n",
    "    get_openai_o4mini_response,\n",
    "### local #################\n",
    "    get_llama_response, \n",
    "    get_qwen_4b_response,                        \n",
    "    #get_deepseek_qwen_response,\n",
    "    # get_qwen_response,\n",
    "    # get_mistral_response,\n",
    "    cleanup_llama,\n",
    "    cleanup_qwen,\n",
    "    cleanup_qwen_4b,\n",
    "    cleanup_deepseek_qwen,\n",
    "    cleanup_mistral,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb3eb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_prompt = \"\"\"\n",
    "### Role\n",
    "You are an expert content moderator specializing in identifying drug-related content on social media.\n",
    "\n",
    "### Task\n",
    "Classify the content as either ILLICIT/ABUSIVE-DRUG-RELATED (True) or NOT ILLICIT/ABUSIVE-DRUG-RELATED (False).\n",
    "Provide a one sentence explanation for your classification.\n",
    "\n",
    "### Output: JSON format\n",
    "{\n",
    "    \"label\": \"True\" or \"False\",\n",
    "    \"explanation\": \"Your reasoning for the classification.\"\n",
    "}       \n",
    "\n",
    "### Definitions\n",
    "True include content that: \n",
    "- Mentions illegal, RX, or OTC drugs in the context of abuse or misuse (using, buying, promoting, etc.) \n",
    "- Uses slang, euphemisms, or cultural references that signal recreational drug use or drugabuse.\n",
    "- Encourages or glorifies drug misuse\n",
    "\n",
    "False include content that:\n",
    "- Mentions drugs in a medical, educational, or preventative context (discouraging)\n",
    "- Uses drug-related terms in a different context or unrelated topics\n",
    "\n",
    "--- Example #1 ---\n",
    "Content: I got her hooked on that lean everyday she say she want codeine\n",
    "{\"label\": \"True\", \"explanation\": \"The content mentions 'lean' and 'codeine,' and explains 'hooked' 'everyday' with an approving, supportive tone..\"}\n",
    "\n",
    "--- Example #2 ---\n",
    " Content: Pharmacology lecture today covered how buprenorphine helps treat opioid addiction\n",
    "{\"label\": \"False\", \"explanation\": \"Educational context discussing medication assisted treatment, no promotion of misuse.\"}\n",
    "\n",
    "(Do NOT include anything except True or False)\n",
    "Content: {{tweet_text}}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2f8bb3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 13 columns):\n",
      " #   Column                     Non-Null Count  Dtype \n",
      "---  ------                     --------------  ----- \n",
      " 0   text                       1000 non-null   object\n",
      " 1   label                      1000 non-null   object\n",
      " 2   tweet_num                  1000 non-null   int64 \n",
      " 3   found_terms                1000 non-null   object\n",
      " 4   found_index_terms          1000 non-null   object\n",
      " 5   GPT_found_terms            1000 non-null   object\n",
      " 6   GPT_found_index_terms      1000 non-null   object\n",
      " 7   pubchem_found_terms        1000 non-null   object\n",
      " 8   pubchem_found_index_terms  1000 non-null   object\n",
      " 9   redmed_found_terms         1000 non-null   object\n",
      " 10  redmed_found_index_terms   1000 non-null   object\n",
      " 11  DEA_found_terms            1000 non-null   object\n",
      " 12  DEA_found_index_terms      1000 non-null   object\n",
      "dtypes: int64(1), object(12)\n",
      "memory usage: 101.7+ KB\n"
     ]
    }
   ],
   "source": [
    "tweets = get_tweets_dataset()\n",
    "SEED = 777\n",
    "tweets = ( tweets.sample(n=1_000, random_state=SEED, replace=False)\n",
    "                 .sort_index()\n",
    "                 .reset_index(drop=True)\n",
    ")\n",
    "tweets.info(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ff0a3f",
   "metadata": {},
   "source": [
    "# RUN 4 MODELS: long_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9787fcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# o4-mini (smarter than GPT-4o-mini)\n",
    "responses = run_prompt_on_llm(get_openai_o4mini_response, \"o4mini\", long_prompt, tweets)\n",
    "#tweets[\"o4mini_response\"] = responses\n",
    "\n",
    "# GPT-4o-mini\n",
    "responses = run_prompt_on_llm(get_openai_gpt4omini_response, \"gpt4omini\", long_prompt, tweets)\n",
    "#tweets[\"4o_mini_response\"] = responses\n",
    "\n",
    "# Meta-Llama-3.1-8B-Instruct\n",
    "responses = run_prompt_on_llm(get_llama_response, \"llama\", long_prompt, tweets)\n",
    "# tweets[\"llama_response\"] = responses\n",
    "cleanup_llama()\n",
    "\n",
    "# Qwen-4B\n",
    "responses = run_prompt_on_llm(get_qwen_4b_response, \"qwen_4b\", long_prompt, tweets)\n",
    "# tweets[\"qwen_4b_response\"] = responses\n",
    "cleanup_qwen_4b()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "519fa8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 14991.70it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 15788.83it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 4548.78it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 14418.57it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 2433.26it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 12358.21it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 4030.53it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 13125.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 25 columns):\n",
      " #   Column                     Non-Null Count  Dtype \n",
      "---  ------                     --------------  ----- \n",
      " 0   text                       1000 non-null   object\n",
      " 1   label                      1000 non-null   object\n",
      " 2   tweet_num                  1000 non-null   int64 \n",
      " 3   found_terms                1000 non-null   object\n",
      " 4   found_index_terms          1000 non-null   object\n",
      " 5   GPT_found_terms            1000 non-null   object\n",
      " 6   GPT_found_index_terms      1000 non-null   object\n",
      " 7   pubchem_found_terms        1000 non-null   object\n",
      " 8   pubchem_found_index_terms  1000 non-null   object\n",
      " 9   redmed_found_terms         1000 non-null   object\n",
      " 10  redmed_found_index_terms   1000 non-null   object\n",
      " 11  DEA_found_terms            1000 non-null   object\n",
      " 12  DEA_found_index_terms      1000 non-null   object\n",
      " 13  4o_mini_response           1000 non-null   object\n",
      " 14  4o_mini_label              1000 non-null   object\n",
      " 15  4o_mini_explanation        1000 non-null   object\n",
      " 16  o4mini_response            1000 non-null   object\n",
      " 17  o4mini_label               1000 non-null   object\n",
      " 18  o4mini_explanation         1000 non-null   object\n",
      " 19  qwen_4b_response           1000 non-null   object\n",
      " 20  qwen_4b_label              1000 non-null   object\n",
      " 21  qwen_4b_explanation        1000 non-null   object\n",
      " 22  llama_response             1000 non-null   object\n",
      " 23  llama_label                1000 non-null   object\n",
      " 24  llama_explanation          1000 non-null   object\n",
      "dtypes: int64(1), object(24)\n",
      "memory usage: 195.4+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Collect responses from saved files, get labels and explanations\n",
    "responses = extract_responses(tweets, \"gpt4omini\")\n",
    "tweets[\"4o_mini_response\"] = responses\n",
    "labels, explanations = extract_JSON_labels_and_explanations(tweets, \"gpt4omini\")\n",
    "tweets[\"4o_mini_label\"] = labels\n",
    "tweets[\"4o_mini_explanation\"] = explanations\n",
    "\n",
    "responses = extract_responses(tweets, \"o4mini\")\n",
    "tweets[\"o4mini_response\"] = responses   \n",
    "labels, explanations = extract_JSON_labels_and_explanations(tweets, \"o4mini\")\n",
    "tweets[\"o4mini_label\"] = labels\n",
    "tweets[\"o4mini_explanation\"] = explanations\n",
    "\n",
    "responses = extract_responses(tweets, \"qwen_4b\")\n",
    "tweets[\"qwen_4b_response\"] = responses\n",
    "labels, explanations = extract_JSON_labels_and_explanations(tweets, \"qwen_4b\")\n",
    "tweets[\"qwen_4b_label\"] = labels\n",
    "tweets[\"qwen_4b_explanation\"] = explanations\n",
    "\n",
    "responses = extract_responses(tweets, \"llama\")\n",
    "tweets[\"llama_response\"] = responses\n",
    "labels, explanations = extract_JSON_labels_and_explanations(tweets, \"llama\")\n",
    "tweets[\"llama_label\"] = labels\n",
    "tweets[\"llama_explanation\"] = explanations\n",
    "\n",
    "tweets.info(verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbc23619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Value counts for 'label':\n",
      "label\n",
      "T    713\n",
      "F    287\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for '4o_mini_label':\n",
      "4o_mini_label\n",
      "False    546\n",
      "True     454\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for 'o4mini_label':\n",
      "o4mini_label\n",
      "False    582\n",
      "True     418\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for 'qwen_4b_label':\n",
      "qwen_4b_label\n",
      "False    568\n",
      "True     432\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for 'llama_label':\n",
      "llama_label\n",
      "True     507\n",
      "False    493\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print value counts for every label column in tweets\n",
    "label_cols = [col for col in tweets.columns if \"label\" in col]\n",
    "for col in label_cols:\n",
    "    print(f\"\\nValue counts for '{col}':\")\n",
    "    print(tweets[col].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7742519e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows where label columns do not all agree: 345\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>4o_mini_label</th>\n",
       "      <th>o4mini_label</th>\n",
       "      <th>qwen_4b_label</th>\n",
       "      <th>llama_label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>The guy was hanged in Singapore because he was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Ex heroin addict here and I endorse this messa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Innovation drives shift in cannabis product de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>When that codeine had u knocked all day, now u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>420 cannabis festival: Weed prepares to host b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  4o_mini_label o4mini_label qwen_4b_label llama_label  \\\n",
       "0          True         True         False        True   \n",
       "1         False        False          True       False   \n",
       "3         False         True         False       False   \n",
       "4          True        False         False        True   \n",
       "5          True         True          True       False   \n",
       "\n",
       "                                                text  \n",
       "0  The guy was hanged in Singapore because he was...  \n",
       "1  Ex heroin addict here and I endorse this messa...  \n",
       "3  Innovation drives shift in cannabis product de...  \n",
       "4  When that codeine had u knocked all day, now u...  \n",
       "5  420 cannabis festival: Weed prepares to host b...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find rows where not all label columns agree (all True or all False)\n",
    "label_cols = [col for col in tweets.columns if \"label\" in col and col != \"label\"]\n",
    "def not_all_agree(row):\n",
    "    vals = [str(row[col]).strip().lower() for col in label_cols]\n",
    "    # Only consider rows where all values are either 'true' or all 'false'\n",
    "    return not (all(v == \"true\" for v in vals) or all(v == \"false\" for v in vals))\n",
    "\n",
    "disagreeing_tweets = tweets[tweets.apply(not_all_agree, axis=1)].copy()\n",
    "print(f\"Number of rows where label columns do not all agree: {len(disagreeing_tweets)}\")\n",
    "disagreeing_tweets[label_cols + [\"text\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7f2d27",
   "metadata": {},
   "outputs": [],
   "source": [
    ":)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamafinetuning5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

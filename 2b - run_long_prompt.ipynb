{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a8a75de",
   "metadata": {},
   "source": [
    "# Long Prompt\n",
    "<br>\n",
    "James Chapman<br>\n",
    "CIS 830 Advanced Topics in AI â€“ Term Project<br>\n",
    "Kansas State University<br><br>\n",
    "\n",
    "This notebook classifies social media posts for ILLICIT/ABUSIVE drug use.<br>\n",
    "\n",
    "- Uses 'long_prompt'\n",
    "- Runs 4 LLMs (2 Paid Services & 2 Local HuggingFace Models)\n",
    "    - o4-mini \n",
    "    - GPT-4o-mini\n",
    "    - Meta-Llama-3.1-8B-Instruct\n",
    "    - Qwen-4B\n",
    "\n",
    "*** Saves response from every LLM call in separate text files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4579da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from utils import (\n",
    "    get_tweets_dataset, \n",
    "    extract_responses,\n",
    "    extract_JSON_labels_and_explanations,\n",
    "    extract_drug_labels,\n",
    "    extract_T_F_labels, \n",
    "    match_terms,\n",
    "    get_confusion_matrix_and_metrics,\n",
    ")\n",
    "from llm_manager import (\n",
    "    run_prompt_on_llm,\n",
    "### paid #################\n",
    "    # get_claude_response, \n",
    "    # get_openai_response, \n",
    "    # get_perplexity_response,\n",
    "    get_openai_gpt4omini_response,\n",
    "    get_openai_o4mini_response,\n",
    "### local #################\n",
    "    get_llama_response, \n",
    "    get_qwen_4b_response,                        \n",
    "    #get_deepseek_qwen_response,\n",
    "    # get_qwen_response,\n",
    "    # get_mistral_response,\n",
    "    cleanup_llama,\n",
    "    cleanup_qwen,\n",
    "    cleanup_qwen_4b,\n",
    "    cleanup_deepseek_qwen,\n",
    "    cleanup_mistral,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb3eb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_prompt = \"\"\"\n",
    "### Role\n",
    "You are an expert content moderator specializing in identifying drug-related content on social media.\n",
    "\n",
    "### Task\n",
    "Classify the content as either ILLICIT/ABUSIVE-DRUG-RELATED (True) or NOT ILLICIT/ABUSIVE-DRUG-RELATED (False).\n",
    "Provide a one sentence explanation for your classification.\n",
    "\n",
    "### Output: JSON format\n",
    "{\n",
    "    \"label\": \"True\" or \"False\",\n",
    "    \"explanation\": \"Your reasoning for the classification.\"\n",
    "}       \n",
    "\n",
    "### Definitions\n",
    "True include content that: \n",
    "- Mentions illegal, RX, or OTC drugs in the context of abuse or misuse (using, buying, promoting, etc.) \n",
    "- Uses slang, euphemisms, or cultural references that signal recreational drug use or drugabuse.\n",
    "- Encourages or glorifies drug misuse\n",
    "\n",
    "False include content that:\n",
    "- Mentions drugs in a medical, educational, or preventative context (discouraging)\n",
    "- Uses drug-related terms in a different context or unrelated topics\n",
    "\n",
    "--- Example #1 ---\n",
    "Content: I got her hooked on that lean everyday she say she want codeine\n",
    "{\"label\": \"True\", \"explanation\": \"The content mentions 'lean' and 'codeine,' and explains 'hooked' 'everyday' with an approving, supportive tone..\"}\n",
    "\n",
    "--- Example #2 ---\n",
    " Content: Pharmacology lecture today covered how buprenorphine helps treat opioid addiction\n",
    "{\"label\": \"False\", \"explanation\": \"Educational context discussing medication assisted treatment, no promotion of misuse.\"}\n",
    "\n",
    "(Do NOT include anything except True or False)\n",
    "Content: {{tweet_text}}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2f8bb3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 13 columns):\n",
      " #   Column                     Non-Null Count  Dtype \n",
      "---  ------                     --------------  ----- \n",
      " 0   text                       1000 non-null   object\n",
      " 1   label                      1000 non-null   object\n",
      " 2   tweet_num                  1000 non-null   int64 \n",
      " 3   found_terms                1000 non-null   object\n",
      " 4   found_index_terms          1000 non-null   object\n",
      " 5   GPT_found_terms            1000 non-null   object\n",
      " 6   GPT_found_index_terms      1000 non-null   object\n",
      " 7   pubchem_found_terms        1000 non-null   object\n",
      " 8   pubchem_found_index_terms  1000 non-null   object\n",
      " 9   redmed_found_terms         1000 non-null   object\n",
      " 10  redmed_found_index_terms   1000 non-null   object\n",
      " 11  DEA_found_terms            1000 non-null   object\n",
      " 12  DEA_found_index_terms      1000 non-null   object\n",
      "dtypes: int64(1), object(12)\n",
      "memory usage: 101.7+ KB\n"
     ]
    }
   ],
   "source": [
    "tweets = get_tweets_dataset()\n",
    "SEED = 777\n",
    "tweets = ( tweets.sample(n=1_000, random_state=SEED, replace=False)\n",
    "                 .sort_index()\n",
    "                 .reset_index(drop=True)\n",
    ")\n",
    "tweets.info(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ff0a3f",
   "metadata": {},
   "source": [
    "# RUN 4 MODELS: long_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9787fcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# o4-mini (smarter than GPT-4o-mini)\n",
    "responses = run_prompt_on_llm(get_openai_o4mini_response, \"o4mini\", long_prompt, tweets)\n",
    "#tweets[\"o4mini_response\"] = responses\n",
    "\n",
    "# GPT-4o-mini\n",
    "responses = run_prompt_on_llm(get_openai_gpt4omini_response, \"gpt4omini\", long_prompt, tweets)\n",
    "#tweets[\"4o_mini_response\"] = responses\n",
    "\n",
    "# Meta-Llama-3.1-8B-Instruct\n",
    "responses = run_prompt_on_llm(get_llama_response, \"llama\", long_prompt, tweets)\n",
    "# tweets[\"llama_response\"] = responses\n",
    "cleanup_llama()\n",
    "\n",
    "# Qwen-4B\n",
    "responses = run_prompt_on_llm(get_qwen_4b_response, \"qwen_4b\", long_prompt, tweets)\n",
    "# tweets[\"qwen_4b_response\"] = responses\n",
    "cleanup_qwen_4b()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7f2d27",
   "metadata": {},
   "outputs": [],
   "source": [
    ":)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamafinetuning5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

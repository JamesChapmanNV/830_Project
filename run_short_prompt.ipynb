{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e4579da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from utils import (\n",
    "    get_tweets_dataset, \n",
    "    extract_responses,\n",
    "    extract_JSON_labels_and_explanations,\n",
    "    extract_drug_labels,\n",
    "    extract_T_F_labels, \n",
    "    match_terms,\n",
    "    get_confusion_matrix_and_metrics,\n",
    ")\n",
    "from llm_manager import (\n",
    "    run_prompt_on_llm,\n",
    "### paid #################\n",
    "    # get_claude_response, \n",
    "    # get_openai_response, \n",
    "    # get_perplexity_response,\n",
    "    get_openai_gpt4omini_response,\n",
    "    get_openai_o4mini_response,\n",
    "### local #################\n",
    "    get_llama_response, \n",
    "    get_qwen_4b_response,                        \n",
    "    #get_deepseek_qwen_response,\n",
    "    # get_qwen_response,\n",
    "    # get_mistral_response,\n",
    "    cleanup_llama,\n",
    "    cleanup_qwen,\n",
    "    cleanup_qwen_4b,\n",
    "    cleanup_deepseek_qwen,\n",
    "    cleanup_mistral,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2f8bb3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 13 columns):\n",
      " #   Column                     Non-Null Count  Dtype \n",
      "---  ------                     --------------  ----- \n",
      " 0   text                       1000 non-null   object\n",
      " 1   label                      1000 non-null   object\n",
      " 2   tweet_num                  1000 non-null   int64 \n",
      " 3   found_terms                1000 non-null   object\n",
      " 4   found_index_terms          1000 non-null   object\n",
      " 5   GPT_found_terms            1000 non-null   object\n",
      " 6   GPT_found_index_terms      1000 non-null   object\n",
      " 7   pubchem_found_terms        1000 non-null   object\n",
      " 8   pubchem_found_index_terms  1000 non-null   object\n",
      " 9   redmed_found_terms         1000 non-null   object\n",
      " 10  redmed_found_index_terms   1000 non-null   object\n",
      " 11  DEA_found_terms            1000 non-null   object\n",
      " 12  DEA_found_index_terms      1000 non-null   object\n",
      "dtypes: int64(1), object(12)\n",
      "memory usage: 101.7+ KB\n"
     ]
    }
   ],
   "source": [
    "tweets = get_tweets_dataset()\n",
    "SEED = 777\n",
    "tweets = ( tweets.sample(n=1_000, random_state=SEED, replace=False)\n",
    "                 .sort_index()\n",
    "                 .reset_index(drop=True)\n",
    ")\n",
    "tweets.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "beb3eb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_prompt = \"\"\"You moderate social‑media posts for drug abuse.\n",
    "\n",
    "Label rules  \n",
    "T – text shows illicit or abusive drug use (using, seeking, buying, selling, trafficking, or slang for drugs).  \n",
    "F – all other cases (medical/policy discussion, news, discouraging use, metaphor).\n",
    "\n",
    "Return only **T** or **F**, no additional text, reasoning, or explanation.\n",
    "\n",
    "Post: \"{{tweet_text}}\"\n",
    "Label:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e72433f",
   "metadata": {},
   "source": [
    "# RUN 4 MODELS: short_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1569ef7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [48:41<00:00,  2.92s/it] \n",
      "100%|██████████| 1000/1000 [11:08<00:00,  1.50it/s]\n"
     ]
    }
   ],
   "source": [
    "# o4-mini (smarter than GPT-4o-mini)\n",
    "responses = run_prompt_on_llm(get_openai_o4mini_response, \"o4mini_short\", short_prompt, tweets)\n",
    "#tweets[\"o4mini_response\"] = responses\n",
    "\n",
    "# GPT-4o-mini\n",
    "responses = run_prompt_on_llm(get_openai_gpt4omini_response, \"gpt4omini_short\", short_prompt, tweets)\n",
    "#tweets[\"4o_mini_response\"] = responses\n",
    "\n",
    "# Meta-Llama-3.1-8B-Instruct\n",
    "responses = run_prompt_on_llm(get_llama_response, \"llama_short\", short_prompt, tweets)\n",
    "# tweets[\"llama_response\"] = responses\n",
    "cleanup_llama()\n",
    "\n",
    "# Qwen-4B\n",
    "responses = run_prompt_on_llm(get_qwen_4b_response, \"qwen_4b_short\", short_prompt, tweets)\n",
    "# tweets[\"qwen_4b_response\"] = responses\n",
    "cleanup_qwen_4b()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "519fa8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 15990.67it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 15179.26it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 16524.91it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 10912.92it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 8528.23it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 10293.33it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 15997.86it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 15239.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 21 columns):\n",
      " #   Column                     Non-Null Count  Dtype \n",
      "---  ------                     --------------  ----- \n",
      " 0   text                       1000 non-null   object\n",
      " 1   label                      1000 non-null   object\n",
      " 2   tweet_num                  1000 non-null   int64 \n",
      " 3   found_terms                1000 non-null   object\n",
      " 4   found_index_terms          1000 non-null   object\n",
      " 5   GPT_found_terms            1000 non-null   object\n",
      " 6   GPT_found_index_terms      1000 non-null   object\n",
      " 7   pubchem_found_terms        1000 non-null   object\n",
      " 8   pubchem_found_index_terms  1000 non-null   object\n",
      " 9   redmed_found_terms         1000 non-null   object\n",
      " 10  redmed_found_index_terms   1000 non-null   object\n",
      " 11  DEA_found_terms            1000 non-null   object\n",
      " 12  DEA_found_index_terms      1000 non-null   object\n",
      " 13  4o_mini_response_short     1000 non-null   object\n",
      " 14  4o_mini_label_short        1000 non-null   object\n",
      " 15  o4mini_response_short      1000 non-null   object\n",
      " 16  o4mini_label_short         1000 non-null   object\n",
      " 17  qwen_4b_response_short     1000 non-null   object\n",
      " 18  qwen_4b_label_short        1000 non-null   object\n",
      " 19  llama_response_short       1000 non-null   object\n",
      " 20  llama_label_short          1000 non-null   object\n",
      "dtypes: int64(1), object(20)\n",
      "memory usage: 164.2+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Collect responses from saved files, get labels\n",
    "responses = extract_responses(tweets, \"gpt4omini_short\")\n",
    "tweets[\"4o_mini_response_short\"] = responses\n",
    "labels = extract_T_F_labels(tweets, \"gpt4omini_short\")\n",
    "tweets[\"4o_mini_label_short\"] = labels\n",
    "\n",
    "responses = extract_responses(tweets, \"o4mini_short\")\n",
    "tweets[\"o4mini_response_short\"] = responses   \n",
    "labels = extract_T_F_labels(tweets, \"o4mini_short\")\n",
    "tweets[\"o4mini_label_short\"] = labels\n",
    "\n",
    "responses = extract_responses(tweets, \"qwen_4b_short\")\n",
    "tweets[\"qwen_4b_response_short\"] = responses\n",
    "labels = extract_T_F_labels(tweets, \"qwen_4b_short\")\n",
    "tweets[\"qwen_4b_label_short\"] = labels\n",
    "\n",
    "responses = extract_responses(tweets, \"llama_short\")\n",
    "tweets[\"llama_response_short\"] = responses\n",
    "labels = extract_T_F_labels(tweets, \"llama_short\")\n",
    "tweets[\"llama_label_short\"] = labels\n",
    "\n",
    "tweets.info(verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbc23619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Value counts for 'label':\n",
      "label\n",
      "T    713\n",
      "F    287\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for '4o_mini_label_short':\n",
      "4o_mini_label_short\n",
      "F    580\n",
      "T    420\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for 'o4mini_label_short':\n",
      "o4mini_label_short\n",
      "F    581\n",
      "T    419\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for 'qwen_4b_label_short':\n",
      "qwen_4b_label_short\n",
      "T    529\n",
      "F    471\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for 'llama_label_short':\n",
      "llama_label_short\n",
      "F    561\n",
      "T    439\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print value counts for every label column in tweets\n",
    "label_cols = [col for col in tweets.columns if \"label\" in col]\n",
    "for col in label_cols:\n",
    "    print(f\"\\nValue counts for '{col}':\")\n",
    "    print(tweets[col].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7742519e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows where label columns do not all agree: 1000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>4o_mini_label_short</th>\n",
       "      <th>o4mini_label_short</th>\n",
       "      <th>qwen_4b_label_short</th>\n",
       "      <th>llama_label_short</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>The guy was hanged in Singapore because he was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>Ex heroin addict here and I endorse this messa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>Yeah, my uncle's GF died a horribly painful, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>Innovation drives shift in cannabis product de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>When that codeine had u knocked all day, now u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  4o_mini_label_short o4mini_label_short qwen_4b_label_short  \\\n",
       "0                   F                  T                   T   \n",
       "1                   F                  T                   T   \n",
       "2                   F                  F                   F   \n",
       "3                   F                  T                   F   \n",
       "4                   T                  T                   F   \n",
       "\n",
       "  llama_label_short                                               text  \n",
       "0                 F  The guy was hanged in Singapore because he was...  \n",
       "1                 F  Ex heroin addict here and I endorse this messa...  \n",
       "2                 F  Yeah, my uncle's GF died a horribly painful, s...  \n",
       "3                 F  Innovation drives shift in cannabis product de...  \n",
       "4                 T  When that codeine had u knocked all day, now u...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find rows where not all label columns agree (all True or all False)\n",
    "label_cols = [col for col in tweets.columns if \"label\" in col and col != \"label\"]\n",
    "def not_all_agree(row):\n",
    "    vals = [str(row[col]).strip().lower() for col in label_cols]\n",
    "    # Only consider rows where all values are either 'true' or all 'false'\n",
    "    return not (all(v == \"true\" for v in vals) or all(v == \"false\" for v in vals))\n",
    "\n",
    "disagreeing_tweets = tweets[tweets.apply(not_all_agree, axis=1)].copy()\n",
    "print(f\"Number of rows where label columns do not all agree: {len(disagreeing_tweets)}\")\n",
    "disagreeing_tweets[label_cols + [\"text\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1873b816",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.to_csv(\"data/tweets_with_short_prompt_results.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "disagreeing_tweets.to_csv(\"data/disagreeing_tweets_short.csv\", index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7f2d27",
   "metadata": {},
   "outputs": [],
   "source": [
    ":)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5cf7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_prompt = \"\"\"\n",
    "Classify the following social media content regarding drug references as either illicit/abusive drug-related (**True**) or not (**False**).\n",
    "\n",
    "Output **only** the single word: **True** or **False**. Do not include any other text, punctuation, or formatting.\n",
    "\n",
    "**Definitions:**\n",
    "**True** (Illicit/Abusive Drug-Related): Content mentioning illegal, RX, or OTC drugs in context of abuse (using, buying, promoting), using slang for recreational use, or glorifying misuse.\n",
    "**False** (Not Illicit/Abusive Drug-Related): Content mentioning drugs in medical/educational/prevention context (discouraging), or using drug terms metaphorically/in unrelated topics.\n",
    "\n",
    "**Examples:**\n",
    "Content: `I got her hooked on that lean everyday she say she want codeine`\n",
    "True\n",
    "\n",
    "Content: `All me and Tyler do is crack on each other lmfao`\n",
    "False\n",
    "\n",
    "Content:{{tweet_text}}\n",
    "\"\"\"\n",
    "short_prompt = \"\"\"\n",
    "You are an expert content‑moderator.  \n",
    "Respond with **only** the word: True or False.\n",
    "\n",
    "• True = mentions illegal / Rx / OTC drugs in a misuse context (use, buy, sell, slang, glorify).  \n",
    "• False = medical, educational, preventative, or unrelated use of drug terms.\n",
    "\n",
    "Content: {{tweet_text}}\n",
    "\"\"\"\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamafinetuning5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
